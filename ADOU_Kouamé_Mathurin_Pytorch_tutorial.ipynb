{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADOU_Kouamé_Mathurin_Pytorch tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKMADOU/Pytorch_tutorial/blob/main/ADOU_Kouam%C3%A9_Mathurin_Pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## what is Pytorch\n",
        "\n",
        "![picture](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/09/pytorch.png)\n",
        "\n",
        "PyTorch is a Python-based library used to build neural networks.\n",
        "\n",
        "It provides classes that allow us to easily develop a suite of deep learning models.\n",
        "\n",
        "It gives maximum flexibility and speed."
      ],
      "metadata": {
        "id": "hnZfVGFOPAWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install pytorch"
      ],
      "metadata": {
        "id": "d_MRnaAiO_Yf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "_inaDm29O2Cs"
      },
      "outputs": [],
      "source": [
        "#!conda install pytorch torchvision -c pytorch\n",
        "# # or with GPU\n",
        "#! conda install pytorch torchvision cudatoolkit=10.1 -c pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let's import pytorch and check that it's well installed"
      ],
      "metadata": {
        "id": "ZevvX0TWROTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kdo2d-DRHEb",
        "outputId": "7dcda881-2007-44e4-e394-8eece7ea8635"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "\n",
        "At its core, PyTorch is a library for processing tensors. Tensors are multidimensional arrays. And PyTorch tensors are similar to NumPy’s n-dimensional arrays. We can use these tensors on a GPU as well (this is not the case with NumPy arrays). This is a major advantage of using tensors. A tensor can be a number, vector, matrix, or any n-dimensional array\n",
        "\n",
        "PyTorch supports multiple types of tensors, including:\n",
        "\n",
        "1. FloatTensor: 32-bit float\n",
        "2. DoubleTensor: 64-bit float\n",
        "3. HalfTensor: 16-bit float\n",
        "4. IntTensor: 32-bit int\n",
        "5. LongTensor: 64-bit int\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Let's create a tensor with a single number."
      ],
      "metadata": {
        "id": "gb5_9wjcRk-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number\n",
        "t1 = torch.tensor(4.)\n",
        "print(t1.dtype)\n",
        "print(t1)\n",
        "print(t1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMLcJ1riRK_o",
        "outputId": "c98817e3-ab59-4995-9b10-0453899eeae4"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor(4.)\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1d tensor(vector)\n",
        "t2 = torch.tensor([1., 2, 3, 4])\n",
        "print(t2)\n",
        "print(t2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz8NW_6CTxhY",
        "outputId": "5b0a2db9-7461-4ce6-e142-94f6de173d72"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.tensor([[2,3,4],\n",
        "               [9,0,2],[948,98,38]])\n",
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAnZMLukQ3S0",
        "outputId": "8773a7a1-9f62-4d2a-ff3e-b6e75dfaa17d"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2d tensor or matrix\n",
        "\n",
        "# Matrix\n",
        "t3 = torch.tensor([[5., 6], \n",
        "                   [7, 8], \n",
        "                   [9, 10]])\n",
        "print(t3)\n",
        "print(t3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we39aYDhUDVX",
        "outputId": "f6afb2f2-66ad-4790-8774-e1eab9af7d9e"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n",
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3d tensor\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13], \n",
        "     [13, 14, 15]], \n",
        "    [[15, 16, 17], \n",
        "     [17, 18, 19.]]])\n",
        "print(t4)\n",
        "print(t4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M7aIMQ3URZb",
        "outputId": "c39cc42d-7f4b-41b7-c3c7-6099bb786b20"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[11., 12., 13.],\n",
            "         [13., 14., 15.]],\n",
            "\n",
            "        [[15., 16., 17.],\n",
            "         [17., 18., 19.]]])\n",
            "torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mathematical operations on tensors"
      ],
      "metadata": {
        "id": "LXyky65lYfti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a =  torch.tensor([1., 2, 3, 4])\n",
        "b =  torch.tensor([5., 6, 7, 8])\n",
        "\n",
        "print(\"===========sum of a and b=============\")\n",
        "\n",
        "print(a + b)\n",
        "print()\n",
        "print(\"===========substracting a from b======\")\n",
        "\n",
        "print(b - a)\n",
        "print()\n",
        "\n",
        "print(\"===========multiplying a and b=========\")\n",
        "\n",
        "print(a * b)\n",
        "print()\n",
        "print(\"===========dividing b per a=============\")\n",
        "\n",
        "print(b/a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46O1PQoGYsdB",
        "outputId": "14578812-6348-4b19-c8b0-17313445d6b2"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========sum of a and b=============\n",
            "tensor([ 6.,  8., 10., 12.])\n",
            "\n",
            "===========substracting a from b======\n",
            "tensor([4., 4., 4., 4.])\n",
            "\n",
            "===========multiplying a and b=========\n",
            "tensor([ 5., 12., 21., 32.])\n",
            "\n",
            "===========dividing b per a=============\n",
            "tensor([5.0000, 3.0000, 2.3333, 2.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Initialization\n",
        "\n",
        "### Create  a matrix of shape 3*3 having all zeros"
      ],
      "metadata": {
        "id": "kXkVQbMFVSz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = torch.zeros((3,3))\n",
        "print(m1)\n",
        "print(m1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7xrWyWkUcGV",
        "outputId": "2123429c-8edc-47d5-9995-c80570211182"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create  a matrix of shape 3*3 having all ones"
      ],
      "metadata": {
        "id": "pPqIZztFWdml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = torch.ones((3,3))\n",
        "print(m2)\n",
        "print(m2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiFaNzqaWXwI",
        "outputId": "dfc30672-e2b4-4371-9a7f-8c908c0195fb"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create  a 3x3 matrix randomly filled"
      ],
      "metadata": {
        "id": "Qyii4eTyWmmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the random seed for pytorch\n",
        "torch.manual_seed(42)\n",
        "# matrix of random numbers\n",
        "## torch.randn returns a tensor filled with random numbers from a normal distribution with mean `0` and variance `1`\n",
        "m3 = torch.randn(3,3)\n",
        "print(m3)\n",
        "print(m3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIoyR8Y5WkZc",
        "outputId": "f28bf584-b288-467d-c343-34afe8231dff"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3367,  0.1288,  0.2345],\n",
            "        [ 0.2303, -1.1229, -0.1863],\n",
            "        [ 2.2082, -0.6380,  0.4617]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.randint returns a tensor filled with random integers generated uniformly\n",
        "m4 = torch.randint(1, 10, (3,3))\n",
        "print(m4)\n",
        "print(m4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HkKAfVMXBeZ",
        "outputId": "6eaecb25-a98d-4f7d-9e39-368fe8fc71c4"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 9, 2],\n",
            "        [6, 9, 5],\n",
            "        [3, 1, 2]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## torch.rand returns a tensor filled with random numbers from a uniform distribution on the interval `[0, 1)`\n",
        "# torch.manual_seed(3)\n",
        "m5 = torch.rand((3,3))\n",
        "print(m5)\n",
        "print(m5.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITbrfl6CXTHz",
        "outputId": "048220fb-138b-4187-f67d-0d70f3a6b81c"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0062, 0.9516, 0.0753],\n",
            "        [0.8860, 0.5832, 0.3376],\n",
            "        [0.8090, 0.5779, 0.9040]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix operations"
      ],
      "metadata": {
        "id": "iNm_40gDZsL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(3,3)\n",
        "b = torch.randn(3,3)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PgIwWjTXi5E",
        "outputId": "db7c8819-ab40-4ff5-8ef1-d96bdd8af27d"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3367,  0.1288,  0.2345],\n",
            "        [ 0.2303, -1.1229, -0.1863],\n",
            "        [ 2.2082, -0.6380,  0.4617]])\n",
            "tensor([[ 0.2674,  0.5349,  0.8094],\n",
            "        [ 1.1103, -1.6898, -0.9890],\n",
            "        [ 0.9580,  1.3221,  0.8172]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For addition, substraction and division we can either use torch.add, torch.sub, torch.div or +,  - and /"
      ],
      "metadata": {
        "id": "ASQCTLoGav7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum = torch.add(a, b)\n",
        "print(sum)\n",
        "print()\n",
        "print(a+b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTSGb7o2aJwi",
        "outputId": "79f70f26-cead-48e3-fc11-b5467f45f48c"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6040,  0.6637,  1.0438],\n",
            "        [ 1.3406, -2.8127, -1.1753],\n",
            "        [ 3.1662,  0.6841,  1.2788]])\n",
            "\n",
            "tensor([[ 0.6040,  0.6637,  1.0438],\n",
            "        [ 1.3406, -2.8127, -1.1753],\n",
            "        [ 3.1662,  0.6841,  1.2788]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = torch.sub(a, b)\n",
        "print(sub)\n",
        "print()\n",
        "print(a-b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1pVCjXYaUdF",
        "outputId": "819a8cfc-ab4f-40f9-c45f-b8ed7b1fe47b"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0693, -0.4061, -0.5749],\n",
            "        [-0.8800,  0.5669,  0.8026],\n",
            "        [ 1.2502, -1.9601, -0.3555]])\n",
            "\n",
            "tensor([[ 0.0693, -0.4061, -0.5749],\n",
            "        [-0.8800,  0.5669,  0.8026],\n",
            "        [ 1.2502, -1.9601, -0.3555]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "div = torch.div(a, b)\n",
        "print(div)\n",
        "print()\n",
        "print(a/b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYSAawm9bBR3",
        "outputId": "9cc3f9ad-5850-4f85-8528-e542fd2b30df"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2594,  0.2408,  0.2897],\n",
            "        [ 0.2075,  0.6645,  0.1884],\n",
            "        [ 2.3051, -0.4826,  0.5649]])\n",
            "\n",
            "tensor([[ 1.2594,  0.2408,  0.2897],\n",
            "        [ 0.2075,  0.6645,  0.1884],\n",
            "        [ 2.3051, -0.4826,  0.5649]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiplication\n",
        "\n",
        "### Elementwise multiplication"
      ],
      "metadata": {
        "id": "7kRIG9QBba30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mult = a*b\n",
        "print(mult)\n",
        "print()\n",
        "print(mult.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3degTw-bJsG",
        "outputId": "f4dcd2fe-16d7-405e-908f-f156576083b5"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0900,  0.0689,  0.1898],\n",
            "        [ 0.2557,  1.8974,  0.1843],\n",
            "        [ 2.1154, -0.8435,  0.3773]])\n",
            "\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### matrix multiplication"
      ],
      "metadata": {
        "id": "aMwc8LAIcU7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mult = torch.mm(a, b)\n",
        "print(mult)\n",
        "print()\n",
        "print(mult.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd53sJ0Sbd9q",
        "outputId": "732ac349-d85e-45e8-f799-be9706421336"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4576,  0.2724,  0.3367],\n",
            "        [-1.3636,  1.7743,  1.1446],\n",
            "        [ 0.3243,  2.8696,  2.7954]])\n",
            "\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mult = torch.matmul(a, b)\n",
        "print(mult)\n",
        "print()\n",
        "print(mult.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccr4aoIWb0iS",
        "outputId": "d9ee2bb7-502a-45ad-c3be-c275395e1e1b"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4576,  0.2724,  0.3367],\n",
            "        [-1.3636,  1.7743,  1.1446],\n",
            "        [ 0.3243,  2.8696,  2.7954]])\n",
            "\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mult = a @ b\n",
        "print(mult)\n",
        "print()\n",
        "print(mult.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4qTWQg5cbD_",
        "outputId": "29c26820-acda-4c20-adc7-64ccd18499d7"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4576,  0.2724,  0.3367],\n",
            "        [-1.3636,  1.7743,  1.1446],\n",
            "        [ 0.3243,  2.8696,  2.7954]])\n",
            "\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshape, Transpose and concatenate tensors"
      ],
      "metadata": {
        "id": "VUp-M__Tc9_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(3,4)\n",
        "print(a.shape)\n",
        "b = a.reshape(-1, 1)\n",
        "print(b.shape)\n",
        "c = a.reshape(6,2)\n",
        "print(c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u0m8W2Acfyk",
        "outputId": "4c48dda5-9eb2-43a4-d9db-18a177054753"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.t(a)\n",
        "print(a_t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlkTPfirddD1",
        "outputId": "276ad5e8-312a-4c81-a6b0-aa5cd3c531d4"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.T.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV6zOpsfdmvR",
        "outputId": "0c9a1851-2d06-4b75-a053-a39be9367d76"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=torch.tensor([3,4,5])\n",
        "r=torch.tensor([5,4,2])\n",
        "cont=torch.cat((l,r))\n",
        "print(cont)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBTIi20NU37K",
        "outputId": "4edced6d-e46a-43ac-81ce-e7d82357bcee"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 4, 5, 5, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randn(1, 4)\n",
        "print(b.shape)\n",
        "concat = torch.cat((a, b), dim=0)\n",
        "print(concat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIRKGWBRdoda",
        "outputId": "d6bb8a4b-d75e-4ec1-f29f-1173d2007cb1"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4])\n",
            "torch.Size([4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a=np.array([3.,5,2])\n",
        "torch.from_numpy(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JVjHi2RUpm8",
        "outputId": "cca9fd44-bde2-4451-8e2c-5241608cfb2c"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 5., 2.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_vect = a.flatten()\n",
        "print(flat_vect)\n",
        "flat_vect.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WebTP3YNKBn1",
        "outputId": "31dfe057-f765-4474-fcd6-2ada5b964ebb"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3. 5. 2.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd\n",
        "\n",
        "### PyTorch uses a technique called automatic differentiation. It records all the operations that we are performing and replays it backward to compute gradients\n",
        "### The autograd package provides automatic differentiation for all operations on Tensors"
      ],
      "metadata": {
        "id": "5Gfz6GQaeWHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad = True -> tracks all operations on the tensor. \n",
        "torch.manual_seed(42)\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(y)\n",
        "y.retain_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3Oru6TXd_5h",
        "outputId": "d3e73043-a6aa-4bcb-d0e6-242b6c9f0be7"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367, 0.1288, 0.2345], requires_grad=True)\n",
            "tensor([2.3367, 2.1288, 2.2345], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-ep7mXOjV7a",
        "outputId": "49316053-d05f-499d-9976-e35e2a854b00"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7f052e53ced0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y * 3\n",
        "print(z)\n",
        "h = z.mean()\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Qg94_HkL5I",
        "outputId": "3577fba3-a147-4f95-ad8b-d6898f1b7dde"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([16.3804, 13.5955, 14.9785], grad_fn=<MulBackward0>)\n",
            "tensor(14.9848, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute the gradients with backpropagation\n",
        "When we finish our computation we can call ***.backward()*** and have all the gradients computed automatically.\n",
        "The gradient for this tensor will be accumulated into .grad attribute.\n",
        "It is the partial derivate of the function w.r.t. the tensor.\n",
        "\n",
        "In summary, torch.autograd is an engine for computing vector-Jacobian product\n",
        "It computes partial derivates while applying the chain rule"
      ],
      "metadata": {
        "id": "CItPQk_xkuwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h.backward()\n",
        "print(x.grad) # dh/dx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqOwSvAjkT1d",
        "outputId": "bb9d2f58-674b-42dd-ebda-815235d54b4a"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.6734, 4.2576, 4.4689])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## let's compute the gradient manually\n",
        "\n",
        "$δh/δx  = (δh/δz).(δz/δy).(δy/δx)$\n",
        "\n",
        "$δh/δz = 1/3$\n",
        "\n",
        "$δz/δy = 6y$\n",
        "\n",
        "$δy/δx = 1$\n",
        "\n",
        "$δh/δx = 1/3 * 6y * 1  = 2(x + 2)$"
      ],
      "metadata": {
        "id": "N8nbxK9NnraF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "2*(x + 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFAalYMwlYXw",
        "outputId": "e9d083d8-fe45-45fb-a48c-4c3382d6d534"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.6734, 4.2576, 4.4689], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros gradient"
      ],
      "metadata": {
        "id": "0O6hz6V-lJPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "backward() accumulates the gradient for this tensor into .grad attribute. We need to be careful during optimization !!! Use .zero_() to empty the gradients before a new optimization step so that the parameter will be updated correctly. Otherwise, the gradient would be a combination of the old gradient, which we have already used to update our model parameters, and the newly-computed gradient. It would therefore point in some other direction than the intended direction towards the minimum "
      ],
      "metadata": {
        "id": "AAS6CL97paCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    \n",
        "    print(weights.grad)\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5-WyAqbnkX6",
        "outputId": "1f369ab8-a24f-4da6-d355-fa9ce2b3a290"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "tensor(12., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation"
      ],
      "metadata": {
        "id": "SlJaQIbiu1OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXpyPij3u50R",
        "outputId": "2b305a34-88d0-4345-b4c3-e3ce92c3e661"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch optim module\n",
        "\n",
        "The Optim module in PyTorch has pre-written codes for most of the optimizers that are used while building a neural network. We just have to import them and then they can be used to build models."
      ],
      "metadata": {
        "id": "valeXz_Bslfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the optim module\n",
        "from torch import optim\n",
        "# sgd\n",
        "## SGD = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# adam\n",
        "## adam = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Optimizer has zero_grad() method\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "8S5yX5JUqdnF"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch nn Module\n",
        "\n",
        "It provides an easy and modular way to build and train simple or complex neural networks using Torch:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Simple layers: nn.Linear\n",
        "*   Convolutional layers: nn.Conv1D, nn.Conv2D, ...\n",
        "*   Pooling layers: nn.MaxPool1d, nn.MaxPool2d, ....\n",
        "*   Criterion: nn.MSELoss, nn.CrossEntropyLoss\n",
        "*   Activation functions:  nn.ReLU, nn.Sigmoid, ...\n",
        "*   ....\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aiijWSXM4dcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "OZ3Lj0OAtHW2"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression with pytorch"
      ],
      "metadata": {
        "id": "SzGiW9av55Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BjjbGCRf4q4G"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare data"
      ],
      "metadata": {
        "id": "Gkf-2lzg6cnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n"
      ],
      "metadata": {
        "id": "9Vehiuse6VYE"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfhuDeaT1MTT",
        "outputId": "b0211b33-231e-4379-90af-8a366537bcf9"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-126.2492],\n",
              "        [  50.9288],\n",
              "        [  63.1546],\n",
              "        [   6.0547],\n",
              "        [  -5.7295],\n",
              "        [  -2.7519],\n",
              "        [  58.7036],\n",
              "        [  53.8136],\n",
              "        [ -95.3411],\n",
              "        [  24.6481],\n",
              "        [ -59.4170],\n",
              "        [ -73.4235],\n",
              "        [-104.1627],\n",
              "        [  31.8077],\n",
              "        [ 171.1535],\n",
              "        [ -67.7520],\n",
              "        [ 141.4677],\n",
              "        [ -24.3676],\n",
              "        [  -2.1124],\n",
              "        [ -32.5958],\n",
              "        [ -29.4151],\n",
              "        [ -37.8715],\n",
              "        [-101.8983],\n",
              "        [  46.4129],\n",
              "        [-181.3484],\n",
              "        [ -31.7740],\n",
              "        [  24.1315],\n",
              "        [ 163.9438],\n",
              "        [  10.7737],\n",
              "        [  37.3589],\n",
              "        [   0.9804],\n",
              "        [-120.8857],\n",
              "        [ 138.1994],\n",
              "        [   9.2027],\n",
              "        [ -16.2069],\n",
              "        [  33.2171],\n",
              "        [ -45.6170],\n",
              "        [  -1.7776],\n",
              "        [-105.5628],\n",
              "        [   5.2639],\n",
              "        [  89.5979],\n",
              "        [ 146.1030],\n",
              "        [ -77.7870],\n",
              "        [  -3.8089],\n",
              "        [  60.8120],\n",
              "        [ -97.2027],\n",
              "        [  -1.1599],\n",
              "        [ -43.8825],\n",
              "        [  15.7428],\n",
              "        [ -24.2745],\n",
              "        [ -90.6015],\n",
              "        [ -19.0731],\n",
              "        [-101.7900],\n",
              "        [ -56.5514],\n",
              "        [  52.1697],\n",
              "        [-158.2847],\n",
              "        [  64.5397],\n",
              "        [  84.5210],\n",
              "        [  66.4343],\n",
              "        [  36.8660],\n",
              "        [  37.4378],\n",
              "        [ -82.9171],\n",
              "        [ -21.4183],\n",
              "        [  -5.5435],\n",
              "        [  59.8845],\n",
              "        [   8.3785],\n",
              "        [ -17.1763],\n",
              "        [-160.5090],\n",
              "        [-100.7372],\n",
              "        [  80.3034],\n",
              "        [  69.6496],\n",
              "        [  28.1444],\n",
              "        [   9.7630],\n",
              "        [  41.1250],\n",
              "        [ 176.9283],\n",
              "        [   9.5598],\n",
              "        [  -4.4046],\n",
              "        [ -24.0359],\n",
              "        [  19.1701],\n",
              "        [ 102.4833],\n",
              "        [ 101.5209],\n",
              "        [ -58.5132],\n",
              "        [  17.6877],\n",
              "        [  63.0537],\n",
              "        [-102.3673],\n",
              "        [  -1.6586],\n",
              "        [  64.6626],\n",
              "        [ -44.1299],\n",
              "        [ 117.9966],\n",
              "        [  -4.6317],\n",
              "        [ -76.7146],\n",
              "        [ -67.2816],\n",
              "        [ -12.4644],\n",
              "        [  24.2973],\n",
              "        [  31.4312],\n",
              "        [  34.4411],\n",
              "        [ -74.7682],\n",
              "        [ 160.9960],\n",
              "        [  40.6977],\n",
              "        [  33.4340]])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUoJ0Dki1QJu",
        "outputId": "f7798326-bdc7-4571-cf41-ea32e91bc492"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-126.2492],\n",
              "        [  50.9288],\n",
              "        [  63.1546],\n",
              "        [   6.0547],\n",
              "        [  -5.7295],\n",
              "        [  -2.7519],\n",
              "        [  58.7036],\n",
              "        [  53.8136],\n",
              "        [ -95.3411],\n",
              "        [  24.6481],\n",
              "        [ -59.4170],\n",
              "        [ -73.4235],\n",
              "        [-104.1627],\n",
              "        [  31.8077],\n",
              "        [ 171.1535],\n",
              "        [ -67.7520],\n",
              "        [ 141.4677],\n",
              "        [ -24.3676],\n",
              "        [  -2.1124],\n",
              "        [ -32.5958],\n",
              "        [ -29.4151],\n",
              "        [ -37.8715],\n",
              "        [-101.8983],\n",
              "        [  46.4129],\n",
              "        [-181.3484],\n",
              "        [ -31.7740],\n",
              "        [  24.1315],\n",
              "        [ 163.9438],\n",
              "        [  10.7737],\n",
              "        [  37.3589],\n",
              "        [   0.9804],\n",
              "        [-120.8857],\n",
              "        [ 138.1994],\n",
              "        [   9.2027],\n",
              "        [ -16.2069],\n",
              "        [  33.2171],\n",
              "        [ -45.6170],\n",
              "        [  -1.7776],\n",
              "        [-105.5628],\n",
              "        [   5.2639],\n",
              "        [  89.5979],\n",
              "        [ 146.1030],\n",
              "        [ -77.7870],\n",
              "        [  -3.8089],\n",
              "        [  60.8120],\n",
              "        [ -97.2027],\n",
              "        [  -1.1599],\n",
              "        [ -43.8825],\n",
              "        [  15.7428],\n",
              "        [ -24.2745],\n",
              "        [ -90.6015],\n",
              "        [ -19.0731],\n",
              "        [-101.7900],\n",
              "        [ -56.5514],\n",
              "        [  52.1697],\n",
              "        [-158.2847],\n",
              "        [  64.5397],\n",
              "        [  84.5210],\n",
              "        [  66.4343],\n",
              "        [  36.8660],\n",
              "        [  37.4378],\n",
              "        [ -82.9171],\n",
              "        [ -21.4183],\n",
              "        [  -5.5435],\n",
              "        [  59.8845],\n",
              "        [   8.3785],\n",
              "        [ -17.1763],\n",
              "        [-160.5090],\n",
              "        [-100.7372],\n",
              "        [  80.3034],\n",
              "        [  69.6496],\n",
              "        [  28.1444],\n",
              "        [   9.7630],\n",
              "        [  41.1250],\n",
              "        [ 176.9283],\n",
              "        [   9.5598],\n",
              "        [  -4.4046],\n",
              "        [ -24.0359],\n",
              "        [  19.1701],\n",
              "        [ 102.4833],\n",
              "        [ 101.5209],\n",
              "        [ -58.5132],\n",
              "        [  17.6877],\n",
              "        [  63.0537],\n",
              "        [-102.3673],\n",
              "        [  -1.6586],\n",
              "        [  64.6626],\n",
              "        [ -44.1299],\n",
              "        [ 117.9966],\n",
              "        [  -4.6317],\n",
              "        [ -76.7146],\n",
              "        [ -67.2816],\n",
              "        [ -12.4644],\n",
              "        [  24.2973],\n",
              "        [  31.4312],\n",
              "        [  34.4411],\n",
              "        [ -74.7682],\n",
              "        [ 160.9960],\n",
              "        [  40.6977],\n",
              "        [  33.4340]])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(n_samples, n_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp5LsUg26gdS",
        "outputId": "94cb6eca-9c53-4fac-e76d-e159c51f30fa"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "NYpipihl7P50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "model"
      ],
      "metadata": {
        "id": "w3U9R_ys6uDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0cc5af-bc0e-400c-c33a-0f313d7d0191"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss and optimizer"
      ],
      "metadata": {
        "id": "f8vqMh1T7cno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
      ],
      "metadata": {
        "id": "9gIqng_f7VKw"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "1T5vp2g07q4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred=model.forward(X)   \n",
        "    # compute loss\n",
        "    loss=criterion(y_pred,y)\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()# w=w-lr*dw\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "zl37Iv237hKa",
        "outputId": "2d787c14-1543-4227-e156-1ba4cd370f69"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 3972.3162\n",
            "epoch: 20, loss = 2800.3962\n",
            "epoch: 30, loss = 2001.8270\n",
            "epoch: 40, loss = 1457.5454\n",
            "epoch: 50, loss = 1086.4983\n",
            "epoch: 60, loss = 833.4947\n",
            "epoch: 70, loss = 660.9446\n",
            "epoch: 80, loss = 543.2404\n",
            "epoch: 90, loss = 462.9331\n",
            "epoch: 100, loss = 408.1303\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Dataset\n",
        "\n",
        "PyTorch provides two data primitives: `torch.utils.data.DataLoade`r and `torch.utils.data.Dataset` that allow us to use pre-loaded datasets as well as our own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
        "\n",
        "PyTorch domain libraries provide a number of pre-loaded datasets (such as FashionMNIST) that subclass torch.utils.data.Dataset and implement functions specific to the particular data. \n",
        "\n",
        "Dataset are accessible through  \n",
        "* TorchVision: for images dataset\n",
        "* TorchText: for text datasets\n",
        "* TorchAudio: for audios dataset\n",
        "\n",
        "\n",
        "Here is an example of how to load the Fashion-MNIST\n",
        "\n",
        "`root` is the path where the train/test data is stored,\n",
        "\n",
        "`train` specifies training or test dataset,\n",
        "\n",
        "`download=True` downloads the data from the internet if it’s not available at root.\n",
        "\n",
        "`transform` and target_transform specify the feature and label transformations (convert data to tensor, normalize data, ...(see documentation))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cndwit8l79ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()  \n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "vhU4nmvy8gHq"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mLUmW535o2Q",
        "outputId": "cd1b986e-4a81-4840-f972-00901892db61"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4fu68o15v_c",
        "outputId": "07887c65-525c-45c1-c3cf-ece5957631aa"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=False)\n",
        "first_batch = next(iter(train_dataloader))\n",
        "image, label = first_batch\n",
        "print(image.shape)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIhQzUV08gAY",
        "outputId": "d7ffd73a-0214-4398-fb52-5eddb9ca0f2b"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 28, 28])\n",
            "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Dataset for your files\n",
        "\n",
        "A custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`. "
      ],
      "metadata": {
        "id": "xjcAjd5vCrO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = pd.read_csv('/content/wine.csv')\n",
        "        xy = xy.to_numpy()\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "alAzIhcS8f7T"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "dataset = WineDataset()\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaRC-t1z8fqy",
        "outputId": "98f9735c-fb2e-4f6e-c8b7-44cf46eb4246"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03], dtype=torch.float64) tensor([1.], dtype=torch.float64)\n",
            "torch.Size([13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load whole dataset with DataLoader\n",
        "# shuffle: shuffle data, good for training\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True)\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = dataiter.next()\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMqU9t2p8fnV",
        "outputId": "6c4e7d33-166d-4c46-ee03-8677b4e49acf"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4160e+01, 2.5100e+00, 2.4800e+00, 2.0000e+01, 9.1000e+01, 1.6800e+00,\n",
            "         7.0000e-01, 4.4000e-01, 1.2400e+00, 9.7000e+00, 6.2000e-01, 1.7100e+00,\n",
            "         6.6000e+02],\n",
            "        [1.4390e+01, 1.8700e+00, 2.4500e+00, 1.4600e+01, 9.6000e+01, 2.5000e+00,\n",
            "         2.5200e+00, 3.0000e-01, 1.9800e+00, 5.2500e+00, 1.0200e+00, 3.5800e+00,\n",
            "         1.2900e+03],\n",
            "        [1.4830e+01, 1.6400e+00, 2.1700e+00, 1.4000e+01, 9.7000e+01, 2.8000e+00,\n",
            "         2.9800e+00, 2.9000e-01, 1.9800e+00, 5.2000e+00, 1.0800e+00, 2.8500e+00,\n",
            "         1.0450e+03],\n",
            "        [1.2160e+01, 1.6100e+00, 2.3100e+00, 2.2800e+01, 9.0000e+01, 1.7800e+00,\n",
            "         1.6900e+00, 4.3000e-01, 1.5600e+00, 2.4500e+00, 1.3300e+00, 2.2600e+00,\n",
            "         4.9500e+02]], dtype=torch.float64) tensor([[3.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [2.]], dtype=torch.float64)\n",
            "torch.Size([4, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's see how to train with the dataloader"
      ],
      "metadata": {
        "id": "pYWQdtA4FYpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy Training loop\n",
        "num_epochs = 2\n",
        "n_iterations = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        \n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_crjXXu8fig",
        "outputId": "9f87892b-173c-40c0-9d19-fd65fa84c7f0"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/2, Step 5/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 10/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 15/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 20/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 25/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 30/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 35/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 40/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 45/10| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
            "Epoch: 2/2, Step 5/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 10/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 15/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 20/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 25/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 30/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 35/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 40/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 45/10| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation functions"
      ],
      "metadata": {
        "id": "XPNNUPz98BMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])"
      ],
      "metadata": {
        "id": "vkS1AGFJ8iWm"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid"
      ],
      "metadata": {
        "id": "HyGosyvqH4Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTooUT_O8iDi",
        "outputId": "fd30e430-f620-4a2c-a5cf-3a85f525e3cb"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tanh"
      ],
      "metadata": {
        "id": "nMNTcEdoIAG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWAUCMYs8h8I",
        "outputId": "441ebfd9-6ce2-43b4-a12e-0842d9e21960"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relu"
      ],
      "metadata": {
        "id": "DXLXgwqPIIWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlLEFTbvIK8S",
        "outputId": "27520a51-b275-4ba8-81c9-fdba51333f11"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## leaky relu"
      ],
      "metadata": {
        "id": "tG4ic0eCIQRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwcEErxUIOF-",
        "outputId": "5dbcc018-346e-4599-8faa-86237645cd2d"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#softmax"
      ],
      "metadata": {
        "id": "LyUf339BHwSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJhC_Lvm8iPF",
        "outputId": "3fdd9064-75ab-4e09-e14a-85c1c2351403"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feedforward network"
      ],
      "metadata": {
        "id": "cJtgNdkz8XFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500 \n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n"
      ],
      "metadata": {
        "id": "tFlWUr1p7t7y"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load MNIST dataset from torchvision\n"
      ],
      "metadata": {
        "id": "n-wxOY2BJHz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset \n",
        "\n",
        "## load train dataset\n",
        "training_data = datasets.MNIST(root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()  \n",
        ")\n",
        "\n",
        "## load test dataset\n",
        "\n",
        "test_data =  datasets.MNIST(root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()  \n",
        ")\n",
        "\n",
        "# Create Data loader for train and test\n",
        "train_loader = DataLoader(training_data, batch_size=16, shuffle=False)\n",
        "examples = iter(train_loader)\n",
        "example_data, example_targets = examples.next()\n",
        "print(example_data.shape)\n",
        "print(example_targets)\n",
        "\n",
        "# test_loader =DataLoader(test_data, batch_size=16 ,shuffle=False)\n",
        "# examples = iter(test_loader)\n",
        "# example_data, example_targets = examples.next()\n",
        "# print(example_data.shape)\n",
        "# print(example_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuDIMWKWJC6O",
        "outputId": "2e11885f-9fc9-45fe-b685-779964fe6f8a"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 28, 28])\n",
            "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "S3BRg1caJYgM",
        "outputId": "121bc8ea-ea6d-45dc-8a9c-59e78285cc02"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model using torch nn Module"
      ],
      "metadata": {
        "id": "-WsYUsX7Jh3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ],
      "metadata": {
        "id": "010CHXZOJd1p"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
      ],
      "metadata": {
        "id": "nv-hPXBqJnP_"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "RuJQTQz2JvFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # origin shape: [16, 1, 28, 28]\n",
        "        # resized: [16, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        y_pred=model.forward(images)\n",
        "       # compute loss\n",
        "        loss=criterion(y_pred,labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9p3FM_AJuIZ",
        "outputId": "03e57fef-5b65-452e-e292-334cc840a882"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Loss: 0.3179\n",
            "Epoch [1/2], Loss: 0.1590\n",
            "Epoch [1/2], Loss: 0.5624\n",
            "Epoch [1/2], Loss: 0.3203\n",
            "Epoch [1/2], Loss: 0.4049\n",
            "Epoch [1/2], Loss: 0.3623\n",
            "Epoch [1/2], Loss: 0.1306\n",
            "Epoch [1/2], Loss: 0.4050\n",
            "Epoch [1/2], Loss: 0.2825\n",
            "Epoch [1/2], Loss: 0.3742\n",
            "Epoch [1/2], Loss: 0.6812\n",
            "Epoch [1/2], Loss: 0.1136\n",
            "Epoch [1/2], Loss: 0.4849\n",
            "Epoch [1/2], Loss: 0.0294\n",
            "Epoch [1/2], Loss: 0.1142\n",
            "Epoch [1/2], Loss: 0.0401\n",
            "Epoch [1/2], Loss: 0.1819\n",
            "Epoch [1/2], Loss: 0.0496\n",
            "Epoch [1/2], Loss: 0.0177\n",
            "Epoch [1/2], Loss: 0.1468\n",
            "Epoch [1/2], Loss: 0.0915\n",
            "Epoch [1/2], Loss: 0.0443\n",
            "Epoch [1/2], Loss: 0.0023\n",
            "Epoch [1/2], Loss: 0.0887\n",
            "Epoch [1/2], Loss: 0.1323\n",
            "Epoch [1/2], Loss: 0.0677\n",
            "Epoch [1/2], Loss: 0.1059\n",
            "Epoch [1/2], Loss: 0.0551\n",
            "Epoch [1/2], Loss: 0.0355\n",
            "Epoch [1/2], Loss: 0.0591\n",
            "Epoch [1/2], Loss: 0.2805\n",
            "Epoch [1/2], Loss: 0.0138\n",
            "Epoch [1/2], Loss: 0.0235\n",
            "Epoch [1/2], Loss: 0.0229\n",
            "Epoch [1/2], Loss: 0.0092\n",
            "Epoch [1/2], Loss: 0.0280\n",
            "Epoch [1/2], Loss: 0.0052\n",
            "Epoch [2/2], Loss: 0.2274\n",
            "Epoch [2/2], Loss: 0.0081\n",
            "Epoch [2/2], Loss: 0.0410\n",
            "Epoch [2/2], Loss: 0.1085\n",
            "Epoch [2/2], Loss: 0.4334\n",
            "Epoch [2/2], Loss: 0.1197\n",
            "Epoch [2/2], Loss: 0.0306\n",
            "Epoch [2/2], Loss: 0.0774\n",
            "Epoch [2/2], Loss: 0.1063\n",
            "Epoch [2/2], Loss: 0.0699\n",
            "Epoch [2/2], Loss: 0.2459\n",
            "Epoch [2/2], Loss: 0.0334\n",
            "Epoch [2/2], Loss: 0.4253\n",
            "Epoch [2/2], Loss: 0.0219\n",
            "Epoch [2/2], Loss: 0.0354\n",
            "Epoch [2/2], Loss: 0.0048\n",
            "Epoch [2/2], Loss: 0.0273\n",
            "Epoch [2/2], Loss: 0.1078\n",
            "Epoch [2/2], Loss: 0.0297\n",
            "Epoch [2/2], Loss: 0.0519\n",
            "Epoch [2/2], Loss: 0.0041\n",
            "Epoch [2/2], Loss: 0.0058\n",
            "Epoch [2/2], Loss: 0.0007\n",
            "Epoch [2/2], Loss: 0.0366\n",
            "Epoch [2/2], Loss: 0.0340\n",
            "Epoch [2/2], Loss: 0.0401\n",
            "Epoch [2/2], Loss: 0.0141\n",
            "Epoch [2/2], Loss: 0.0401\n",
            "Epoch [2/2], Loss: 0.0179\n",
            "Epoch [2/2], Loss: 0.0953\n",
            "Epoch [2/2], Loss: 0.0602\n",
            "Epoch [2/2], Loss: 0.0104\n",
            "Epoch [2/2], Loss: 0.0558\n",
            "Epoch [2/2], Loss: 0.0130\n",
            "Epoch [2/2], Loss: 0.0010\n",
            "Epoch [2/2], Loss: 0.0136\n",
            "Epoch [2/2], Loss: 0.0005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader =DataLoader(test_data, batch_size=16 ,shuffle=False)\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = examples.next()\n",
        "print(example_data.shape)\n",
        "print(example_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P8GxpbTjI-v",
        "outputId": "dc355f54-f38a-4e75-816b-66e20871f00a"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 28, 28])\n",
            "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ],
      "metadata": {
        "id": "DJtdpX5XQH7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V06y8gbrKYIC",
        "outputId": "77fde767-a47d-4e45-c3b4-dce57694cc57"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.88333333333334 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading models"
      ],
      "metadata": {
        "id": "2jG9BSotRM-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "QNFs4X5XRQ3I"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJvZDx5dRW_p",
        "outputId": "d680c585-c6d3-48b2-c2f4-4b2412a55906"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra reading\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html"
      ],
      "metadata": {
        "id": "T8zx-Lx-QNDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tdPHkhJQLXhf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}